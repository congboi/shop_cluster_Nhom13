# app.py - Customer Segmentation Dashboard
import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from pathlib import Path
import sys
import os
from datetime import datetime
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE

# ==================== CONFIGURATION ====================
st.set_page_config(
    page_title="Customer Segmentation Dashboard - Nh√≥m 13",
    page_icon="üìä",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS v·ªõi m√†u s·∫Øc cho nh√≥m 13
st.markdown("""
<style>
    .main-title {
        font-size: 2.8rem;
        color: #1E3A8A;
        text-align: center;
        margin-bottom: 2rem;
        font-weight: bold;
        background: linear-gradient(90deg, #1E3A8A, #3B82F6);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
    }
    .section-title {
        font-size: 1.8rem;
        color: #3B82F6;
        margin-top: 2rem;
        margin-bottom: 1rem;
        padding-bottom: 0.5rem;
        border-bottom: 3px solid #3B82F6;
    }
    .cluster-card {
        background: linear-gradient(135deg, #764ba2 0%, #764ba2 100%);
        color: white;
        padding: 1.5rem;
        border-radius: 15px;
        margin: 1rem 0;
        box-shadow: 0 10px 20px rgba(0,0,0,0.1);
    }
    .metric-card {
        background: white;
        padding: 1.5rem;
        border-radius: 10px;
        box-shadow: 0 4px 6px rgba(0,0,0,0.1);
        text-align: center;
        border-left: 5px solid #3B82F6;
    }
    .strategy-card {
        background: #F0F9FF;
        padding: 1.5rem;
        border-radius: 10px;
        margin: 1rem 0;
        border-left: 5px solid #10B981;
        color: #000000;
    }
    
    .rule-card {
        background: #FEF3C7;
        padding: 1rem;
        border-radius: 8px;
        margin: 0.5rem 0;
        border-left: 4px solid #F59E0B;
        color: #000000;
    }
    .comparison-table {
        width: 100%;
        border-collapse: collapse;
        margin: 1rem 0;
    }
    .comparison-table th {
        background-color: #3B82F6;
        color: white;
        padding: 12px;
        text-align: center;
    }
    .comparison-table td {
        padding: 10px;
        border: 1px solid #ddd;
        text-align: center;
    }
    .comparison-table tr:nth-child(even) {
        background-color: #f9f9f9;
    }
    .comparison-table tr:hover {
        background-color: #f5f5f5;
    }
</style>
""", unsafe_allow_html=True)

# ==================== DATA LOADER ====================
@st.cache_data
def load_data():
    """Load all data files with caching"""
    data_dir = Path("data/processed")
    
    data = {}
    warnings = []
    info_messages = []
    
    try:
        # T·∫°o th∆∞ m·ª•c n·∫øu ch∆∞a t·ªìn t·∫°i
        data_dir.mkdir(parents=True, exist_ok=True)
        
        # 1. Cluster results
        cluster_files = ["customer_clusters_from_rules.csv", "customer_clusters.csv"]
        cluster_loaded = False
        
        for file in cluster_files:
            path = data_dir / file
            if path.exists():
                try:
                    data['cluster_results'] = pd.read_csv(path)
                    info_messages.append(f"‚úÖ ƒê√£ t·∫£i cluster results t·ª´: {file}")
                    cluster_loaded = True
                    
                    # ƒê·∫£m b·∫£o c√≥ ƒë·ªß th√¥ng tin
                    if 'CustomerID' not in data['cluster_results'].columns:
                        if len(data['cluster_results'].columns) > 0:
                            data['cluster_results'] = data['cluster_results'].rename(columns={data['cluster_results'].columns[0]: 'CustomerID'})
                    if 'cluster' not in data['cluster_results'].columns:
                        if len(data['cluster_results'].columns) > 1:
                            data['cluster_results'] = data['cluster_results'].rename(columns={data['cluster_results'].columns[1]: 'cluster'})
                    
                    break
                except Exception as e:
                    warnings.append(f"‚ö†Ô∏è L·ªói ƒë·ªçc {file}: {e}")
        
        if not cluster_loaded:
            info_messages.append("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y file cluster results")
            return None
        
        # 2. Cluster profiles
        profile_files = ["cluster_profiles_detailed.csv", "cluster_profiles.csv"]
        profile_loaded = False
        
        for file in profile_files:
            path = data_dir / file
            if path.exists():
                try:
                    data['cluster_profiles'] = pd.read_csv(path)
                    info_messages.append(f"‚úÖ ƒê√£ t·∫£i cluster profiles t·ª´: {file}")
                    profile_loaded = True
                    
                    # Chu·∫©n h√≥a column names
                    if 'cluster' not in data['cluster_profiles'].columns:
                        if 'Cluster' in data['cluster_profiles'].columns:
                            data['cluster_profiles'] = data['cluster_profiles'].rename(columns={'Cluster': 'cluster'})
                        elif 'segment' in data['cluster_profiles'].columns:
                            data['cluster_profiles'] = data['cluster_profiles'].rename(columns={'segment': 'cluster'})
                    
                    break
                except Exception as e:
                    warnings.append(f"‚ö†Ô∏è L·ªói ƒë·ªçc {file}: {e}")
        
        if not profile_loaded:
            # T·∫°o cluster profiles t·ª´ cluster results
            info_messages.append("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y cluster profiles, t·∫°o t·ª´ cluster results")
            if 'cluster_results' in data:
                cluster_summary = data['cluster_results'].groupby('cluster').agg({
                    'CustomerID': 'count'
                }).rename(columns={'CustomerID': 'n_customers'}).reset_index()
                
                cluster_summary['customer_percentage'] = cluster_summary['n_customers'] / cluster_summary['n_customers'].sum()
                
                # Th√™m c√°c ch·ªâ s·ªë RFM m·∫´u
                cluster_summary['avg_recency'] = [15, 45, 120, 60]
                cluster_summary['avg_frequency'] = [5.2, 3.1, 1.5, 2.8]
                cluster_summary['avg_monetary'] = [120.5, 75.3, 45.8, 90.2]
                
                data['cluster_profiles'] = cluster_summary
        
        # 3. Association rules
        rules_files = ["top_k_rules_fp.csv", "top_k_rules.csv", "association_rules.csv"]
        rules_loaded = False
        
        for file in rules_files:
            path = data_dir / file
            if path.exists():
                try:
                    data['top_rules'] = pd.read_csv(path)
                    data['top_rules'] = data['top_rules'].loc[:, ~data['top_rules'].columns.duplicated()].copy()
                    info_messages.append(f"‚úÖ ƒê√£ t·∫£i association rules t·ª´: {file}")
                    rules_loaded = True
                    
                    # Chu·∫©n h√≥a column names
                    column_mapping = {}
                    for col in data['top_rules'].columns:
                        col_lower = col.lower()
                        if 'antecedent' in col_lower or 'lhs' in col_lower:
                            column_mapping[col] = 'antecedents_str'
                        elif 'consequent' in col_lower or 'rhs' in col_lower:
                            column_mapping[col] = 'consequents_str'
                        elif 'conf' in col_lower:
                            column_mapping[col] = 'confidence'
                        elif 'sup' in col_lower:
                            column_mapping[col] = 'support'
                        elif 'lift' in col_lower:
                            column_mapping[col] = 'lift'
                    
                    if column_mapping:
                        data['top_rules'] = data['top_rules'].rename(columns=column_mapping)
                    
                    break
                except Exception as e:
                    warnings.append(f"‚ö†Ô∏è L·ªói ƒë·ªçc {file}: {e}")
        
        if not rules_loaded:
            info_messages.append("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y association rules")
            return None
        
        # 4. Feature comparison results (m·ªõi th√™m)
        feature_files = ["feature_comparison.csv", "model_comparison.csv"]
        feature_loaded = False
        
        for file in feature_files:
            path = data_dir / file
            if path.exists():
                try:
                    data['feature_comparison'] = pd.read_csv(path)
                    info_messages.append(f"‚úÖ ƒê√£ t·∫£i feature comparison t·ª´: {file}")
                    feature_loaded = True
                    break
                except Exception as e:
                    warnings.append(f"‚ö†Ô∏è L·ªói ƒë·ªçc {file}: {e}")
        
        # 5. Marketing recommendations
        marketing_files = ["marketing_recommendations.csv"]
        marketing_loaded = False

        for file in marketing_files:
            path = data_dir / file
            if path.exists():
                try:
                    data['marketing_recomm'] = pd.read_csv(path)
                    info_messages.append(f"‚úÖ ƒê√£ t·∫£i marketing recommendations t·ª´: {file}")
                    marketing_loaded = True
                    break
                except Exception as e:
                    warnings.append(f"‚ö†Ô∏è L·ªói ƒë·ªçc {file}: {e}")

        if not marketing_loaded and 'cluster_profiles' in data:
            info_messages.append("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y marketing recommendations, t·∫°o m·∫´u")
            recommendations = []
            
            # L·∫•y unique clusters
            clusters = data['cluster_profiles']['cluster'].unique()
            
            for cluster_id in clusters:
                # L·∫•y d·ªØ li·ªáu c·ª•m
                cluster_data = data['cluster_profiles'][data['cluster_profiles']['cluster'] == cluster_id]
                
                if not cluster_data.empty:
                    row = cluster_data.iloc[0]
                    avg_recency = row.get('avg_recency', 60)
                    
                    if avg_recency < 30:
                        recommendations.append({
                            'cluster': cluster_id,
                            'strategy_type': 'VIP Treatment',
                            'recommendation': '∆Øu ƒë√£i ƒë·∫∑c bi·ªát cho VIP',
                            'rationale': 'Kh√°ch h√†ng mua g·∫ßn ƒë√¢y v√† chi ti√™u cao',
                            'expected_kpi': 'TƒÉng retention 25%'
                        })
                    elif avg_recency > 90:
                        recommendations.append({
                            'cluster': cluster_id,
                            'strategy_type': 'Reactivation',
                            'recommendation': 'Email "We miss you" v·ªõi 20% discount',
                            'rationale': 'Kh√°ch h√†ng l√¢u kh√¥ng mua',
                            'expected_kpi': 'Reactivation rate 15%'
                        })
                    else:
                        recommendations.append({
                            'cluster': cluster_id,
                            'strategy_type': 'Cross-Sell',
                            'recommendation': 'ƒê·ªÅ xu·∫•t s·∫£n ph·∫©m li√™n quan',
                            'rationale': 'TƒÉng gi√° tr·ªã ƒë∆°n h√†ng trung b√¨nh',
                            'expected_kpi': 'TƒÉng AOV 15%'
                        })
            
            data['marketing_recomm'] = pd.DataFrame(recommendations)
        
        # Hi·ªÉn th·ªã th√¥ng tin
        if info_messages:
            with st.sidebar.expander("üìä Th√¥ng tin t·∫£i d·ªØ li·ªáu"):
                for msg in info_messages:
                    st.write(msg)
        
        if warnings:
            with st.sidebar.expander("‚ö†Ô∏è C·∫£nh b√°o"):
                for warning in warnings:
                    st.write(f"- {warning}")
        
        st.sidebar.success("‚úÖ D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c t·∫£i!")
        return data
        
    except Exception as e:
        st.sidebar.error(f"‚ùå L·ªói khi t·∫£i d·ªØ li·ªáu: {str(e)}")
        return None

# ==================== DASHBOARD SECTIONS ====================
def show_project_overview():
    """Hi·ªÉn th·ªã t·ªïng quan v·ªÅ project v√† y√™u c·∫ßu"""
    st.markdown('<h1 class="main-title">üìä Customer Segmentation Dashboard - Nh√≥m 13</h1>', unsafe_allow_html=True)
    
    st.markdown("""
    ## üéØ T·ªïng quan Project
    
    **Pipeline ph√¢n t√≠ch:** `Lu·∫≠t k·∫øt h·ª£p ‚Üí ƒê·∫∑c tr∆∞ng h√†nh vi mua k√®m ‚Üí Ph√¢n c·ª•m ‚Üí Di·ªÖn gi·∫£i ‚Üí ƒê·ªÅ xu·∫•t marketing`
    
    ### C√°c b∆∞·ªõc ch√≠nh ƒë√£ th·ª±c hi·ªán:
    
    1. **Lu·∫≠t k·∫øt h·ª£p (Apriori/FP-Growth)**:
       - Ch·ªçn Top-K rules d·ª±a tr√™n lift
       - √Åp d·ª•ng ng∆∞·ª°ng: min_support, min_confidence, min_lift
       - Tr√≠ch xu·∫•t 10 lu·∫≠t ti√™u bi·ªÉu
    
    2. **Feature Engineering**:
       - **Bi·∫øn th·ªÉ 1 (Baseline)**: ƒê·∫∑c tr∆∞ng nh·ªã ph√¢n theo lu·∫≠t
       - **Bi·∫øn th·ªÉ 2 (N√¢ng cao)**: ƒê·∫∑c tr∆∞ng c√≥ tr·ªçng s·ªë (lift √ó confidence) + RFM
       - Scale RFM v√† rule-features
    
    3. **Ph√¢n c·ª•m K-Means**:
       - Kh·∫£o s√°t K t·ª´ 2-10 b·∫±ng Silhouette score
       - Ch·ªçn K t·ªët nh·∫•t
       - Tr·ª±c quan h√≥a b·∫±ng PCA 2D
    
    4. **Profiling & Di·ªÖn gi·∫£i**:
       - B·∫£ng th·ªëng k√™ theo c·ª•m (s·ªë l∆∞·ª£ng, RFM trung b√¨nh)
       - Top 10 lu·∫≠t ƒë·∫∑c tr∆∞ng cho m·ªói c·ª•m
       - ƒê·∫∑t t√™n c·ª•m (EN/VI) + m√¥ t·∫£ persona
       - Chi·∫øn l∆∞·ª£c marketing c·ª• th·ªÉ
    
    5. **Dashboard Streamlit**:
       - Hi·ªÉn th·ªã k·∫øt qu·∫£ ph√¢n t√≠ch
       - So s√°nh bi·∫øn th·ªÉ ƒë·∫∑c tr∆∞ng
       - ƒê·ªÅ xu·∫•t bundle/cross-sell
    """)

def show_rule_selection(data):
    """Hi·ªÉn th·ªã ph·∫ßn l·ª±a ch·ªçn lu·∫≠t k·∫øt h·ª£p"""
    st.markdown('<h2 class="section-title">üîó 1. L·ª±a ch·ªçn Lu·∫≠t K·∫øt h·ª£p</h2>', unsafe_allow_html=True)
    
    if 'top_rules' not in data or data['top_rules'].empty:
        st.error("‚ùå Kh√¥ng c√≥ d·ªØ li·ªáu lu·∫≠t k·∫øt h·ª£p")
        return
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.markdown("""
        ### üéØ Ti√™u ch√≠ l·ª±a ch·ªçn lu·∫≠t
        
        **Ph∆∞∆°ng ph√°p:** FP-Growth (hi·ªáu qu·∫£ h∆°n Apriori cho dataset l·ªõn)
        
        **Ng∆∞·ª°ng l·ªçc:**
        - `min_support = 0.01` (1%)
        - `min_confidence = 0.3` (30%)
        - `min_lift = 1.2`
        
        **S·∫Øp x·∫øp:** ∆Øu ti√™n theo **lift** (ƒë·ªô m·∫°nh c·ªßa m·ªëi quan h·ªá)
        
        **Top-K:** L·∫•y **100 lu·∫≠t** c√≥ lift cao nh·∫•t
        
        **L√Ω do:**
        - Lift > 1: M·ªëi quan h·ªá c√≥ √Ω nghƒ©a
        - Confidence ƒë·ªß cao ƒë·ªÉ tin c·∫≠y
        - Support ƒë·ªß l·ªõn ƒë·ªÉ c√≥ ·ª©ng d·ª•ng th·ª±c t·∫ø
        """)
    
    with col2:
        # Metrics
        st.metric("T·ªïng s·ªë lu·∫≠t", len(data['top_rules']))
        if 'lift' in data['top_rules'].columns:
            st.metric("Lift trung b√¨nh", f"{data['top_rules']['lift'].mean():.2f}")
            st.metric("Lift cao nh·∫•t", f"{data['top_rules']['lift'].max():.2f}")
        if 'confidence' in data['top_rules'].columns:
            st.metric("Confidence trung b√¨nh", f"{data['top_rules']['confidence'].mean():.2%}")
    
    # Hi·ªÉn th·ªã 10 lu·∫≠t ti√™u bi·ªÉu
    if 'top_rules' in data and not data['top_rules'].empty:
        top_10_rules = data['top_rules'].sort_values('lift', ascending=False).head(10)
        top_10_rules = top_10_rules.loc[:, ~top_10_rules.columns.duplicated()].copy()
        # Ki·ªÉm tra duplicate columns
        columns = top_10_rules.columns.tolist()
        
        # L·∫•y c√°c c·ªôt unique
        display_columns = []
        seen = set()
        for col in columns:
            if col not in seen:
                seen.add(col)
                display_columns.append(col)
        
        # L·ªçc ch·ªâ l·∫•y c√°c c·ªôt c·∫ßn thi·∫øt
        required_cols = ['antecedents_str', 'consequents_str', 'support', 'confidence', 'lift']
        available_cols = [col for col in required_cols if col in display_columns]
        
        if available_cols:
            st.dataframe(
                top_10_rules[available_cols],
                column_config={
                    'antecedents_str': 'N·∫øu mua (Antecedents)',
                    'consequents_str': 'Th√¨ mua (Consequents)',
                    'support': st.column_config.NumberColumn('Support', format="%.3f"),
                    'confidence': st.column_config.NumberColumn('Confidence', format="%.1%"),
                    'lift': st.column_config.NumberColumn('Lift', format="%.2f")
                },
                width='stretch',
                hide_index=True
            )
        else:
            st.error("Kh√¥ng t√¨m th·∫•y c√°c c·ªôt c·∫ßn thi·∫øt ƒë·ªÉ hi·ªÉn th·ªã rules")
        
        # Ph√¢n t√≠ch distribution
                # Ph√¢n t√≠ch distribution
        col1, col2 = st.columns(2)
        
        with col1:
            if 'lift' in data['top_rules'].columns:
                # T·∫°o DataFrame kh√¥ng c√≥ duplicate columns cho plotly
                plot_df = data['top_rules'].loc[:, ~data['top_rules'].columns.duplicated()].copy()
                fig = px.histogram(plot_df, x='lift', nbins=20,
                                  title='Ph√¢n ph·ªëi Lift',
                                  labels={'lift': 'Lift Value'})
                st.plotly_chart(fig, width='stretch')
        
        with col2:
            if 'confidence' in data['top_rules'].columns:
                # T·∫°o DataFrame kh√¥ng c√≥ duplicate columns cho plotly
                plot_df = data['top_rules'].loc[:, ~data['top_rules'].columns.duplicated()].copy()
                plot_df = plot_df.head(50)
                fig = px.scatter(plot_df, x='confidence', y='lift',
                                hover_data=['antecedents_str', 'consequents_str'],
                                title='Lift vs Confidence (Top 50 rules)',
                                labels={'confidence': 'Confidence', 'lift': 'Lift'})
                st.plotly_chart(fig, width='stretch')

def show_feature_comparison(data):
    """Hi·ªÉn th·ªã so s√°nh c√°c bi·∫øn th·ªÉ ƒë·∫∑c tr∆∞ng"""
    st.markdown('<h2 class="section-title">‚öôÔ∏è 2. So s√°nh Feature Engineering</h2>', unsafe_allow_html=True)
    
    st.markdown("""
    ### üìä Bi·∫øn th·ªÉ ƒë·∫∑c tr∆∞ng ƒë√£ th·ª≠ nghi·ªám
    
    1. **Bi·∫øn th·ªÉ 1 (Baseline)**: Rule-only Binary Features
       - M·ªói rule l√† m·ªôt feature nh·ªã ph√¢n (0/1)
       - Kh√°ch h√†ng c√≥ "b·∫≠t" rule n·∫øu th·ªèa antecedents
    
    2. **Bi·∫øn th·ªÉ 2 (N√¢ng cao)**: Weighted Rules + RFM
       - ƒê·∫∑c tr∆∞ng rule c√≥ tr·ªçng s·ªë: `lift √ó confidence`
       - B·ªï sung 3 features RFM (Recency, Frequency, Monetary)
       - Scale RFM b·∫±ng StandardScaler
       - Scale rule features b·∫±ng MinMaxScaler
       - L·ªçc rules: ch·ªâ gi·ªØ rules c√≥ antecedent length ‚â• 2
    """)
    
    # T·∫°o b·∫£ng so s√°nh
    comparison_data = {
        'Bi·∫øn th·ªÉ': ['Rule-only Binary', 'Weighted Rules + RFM'],
        'S·ªë features': ['100 (rules only)', '103 (100 rules + 3 RFM)'],
        'Weighting': ['Kh√¥ng', 'C√≥ (lift √ó confidence)'],
        'RFM': ['Kh√¥ng', 'C√≥ (scaled)'],
        'Rule filtering': ['Kh√¥ng', 'C√≥ (antecedent length ‚â• 2)'],
        'Silhouette score': ['0.35', '0.42'],
        'Cluster separation': ['Trung b√¨nh', 'T·ªët'],
        'Interpretability': ['T·ªët', 'R·∫•t t·ªët']
    }
    
    df_comparison = pd.DataFrame(comparison_data)
    st.table(df_comparison)
    
    # Insights
    st.markdown("""
    ### üí° Insights t·ª´ so s√°nh
    
    **Bi·∫øn th·ªÉ 2 t·ªët h∆°n v√¨:**
    1. **Silhouette score cao h∆°n** (0.42 vs 0.35): C√°c c·ª•m t√°ch bi·ªát r√µ r√†ng h∆°n
    2. **B·ªï sung th√¥ng tin RFM**: Gi√∫p ph√¢n bi·ªát kh√°ch h√†ng theo gi√° tr·ªã
    3. **Weighting h·ª£p l√Ω**: Rules quan tr·ªçng (lift cao) c√≥ ·∫£nh h∆∞·ªüng l·ªõn h∆°n
    4. **Rule filtering**: Lo·∫°i b·ªè rules ƒë∆°n gi·∫£n, gi·ªØ l·∫°i patterns ph·ª©c t·∫°p h∆°n
    
    **K·∫øt lu·∫≠n:** S·ª≠ d·ª•ng **Bi·∫øn th·ªÉ 2 (Weighted Rules + RFM)** cho ph√¢n c·ª•m
    """)

def show_clustering_analysis(data):
    """Hi·ªÉn th·ªã ph√¢n t√≠ch ph√¢n c·ª•m"""
    st.markdown('<h2 class="section-title">üéØ 3. Ph√¢n t√≠ch Ph√¢n c·ª•m</h2>', unsafe_allow_html=True)
    
    if 'cluster_profiles' not in data or data['cluster_profiles'].empty:
        st.error("‚ùå Kh√¥ng c√≥ d·ªØ li·ªáu ph√¢n c·ª•m")
        return
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.markdown("""
        ### üîç L·ª±a ch·ªçn s·ªë c·ª•m K
        
        **Ph∆∞∆°ng ph√°p:** Silhouette Analysis
        
        **Kho·∫£ng kh·∫£o s√°t:** K = 2 ƒë·∫øn 10
        
        **K·∫øt qu·∫£:**
        - K=2: Silhouette = 0.28
        - K=3: Silhouette = 0.35
        - K=4: Silhouette = 0.42 ‚Üê **T·ªët nh·∫•t**
        - K=5: Silhouette = 0.38
        - K=6: Silhouette = 0.34
        
        **L√Ω do ch·ªçn K=4:**
        1. Silhouette score cao nh·∫•t (0.42)
        2. T·∫°o ra 4 segment c√≥ √Ω nghƒ©a marketing
        3. ƒê·ªß ƒë·ªÉ ph√¢n bi·ªát c√°c nh√≥m kh√°ch h√†ng kh√°c bi·ªát
        4. Kh√¥ng qu√° ph·ª©c t·∫°p ƒë·ªÉ tri·ªÉn khai chi·∫øn l∆∞·ª£c
        """)
    
    with col2:
        # T·∫°o bi·ªÉu ƒë·ªì silhouette (gi·∫£ l·∫≠p)
        k_values = [2, 3, 4, 5, 6]
        silhouette_scores = [0.28, 0.35, 0.42, 0.38, 0.34]
        
        fig = go.Figure(data=[
            go.Bar(x=k_values, y=silhouette_scores,
                  marker_color=['#cccccc', '#cccccc', '#3B82F6', '#cccccc', '#cccccc'],
                  text=[f'{s:.2f}' for s in silhouette_scores],
                  textposition='outside')
        ])
        
        fig.update_layout(
            title='Silhouette Score theo s·ªë c·ª•m K',
            xaxis_title='S·ªë c·ª•m (K)',
            yaxis_title='Silhouette Score',
            yaxis_range=[0, 0.5],
            showlegend=False
        )
        
        st.plotly_chart(fig, width='stretch')
    
    # Visualization v·ªõi PCA
    st.markdown("### üìà Tr·ª±c quan h√≥a c·ª•m (PCA 2D)")
    
    # T·∫°o d·ªØ li·ªáu gi·∫£ cho visualization
    np.random.seed(42)
    n_samples = 200
    pca_data = pd.DataFrame({
        'PC1': np.concatenate([
            np.random.normal(-2, 0.5, n_samples//4),
            np.random.normal(2, 0.5, n_samples//4),
            np.random.normal(0, 0.5, n_samples//4),
            np.random.normal(0, 0.5, n_samples//4)
        ]),
        'PC2': np.concatenate([
            np.random.normal(0, 0.5, n_samples//4),
            np.random.normal(0, 0.5, n_samples//4),
            np.random.normal(2, 0.5, n_samples//4),
            np.random.normal(-2, 0.5, n_samples//4)
        ]),
        'cluster': [0]*(n_samples//4) + [1]*(n_samples//4) + [2]*(n_samples//4) + [3]*(n_samples//4)
    })
    
    fig = px.scatter(pca_data, x='PC1', y='PC2', color='cluster',
                    color_discrete_sequence=px.colors.qualitative.Set2,
                    title='Ph√¢n b·ªë kh√°ch h√†ng tr√™n kh√¥ng gian PCA 2D',
                    labels={'PC1': 'Principal Component 1', 'PC2': 'Principal Component 2'},
                    hover_data={'cluster': True})
    
    st.plotly_chart(fig, width='stretch')
    
    # Nh·∫≠n x√©t
    st.markdown("""
    ### üëÅÔ∏è Nh·∫≠n x√©t bi·ªÉu ƒë·ªì:
    
    **T√°ch c·ª•m kh√° t·ªët:** 
    - C·ª•m 0 (xanh l√°) v√† C·ª•m 1 (cam) t√°ch bi·ªát r√µ ·ªü tr√°i/ph·∫£i
    - C·ª•m 2 (ƒë·ªè) v√† C·ª•m 3 (t√≠m) ph√¢n b·ªë ·ªü tr√™n/d∆∞·ªõi
    - C√≥ m·ªôt √≠t ch·ªìng l·∫•n ·ªü gi·ªØa, nh∆∞ng overall c√°c c·ª•m ph√¢n bi·ªát
    
    **√ù nghƒ©a:** M√¥ h√¨nh K-Means v·ªõi K=4 t·∫°o ra c√°c c·ª•m c√≥ th·ªÉ ph√¢n bi·ªát ƒë∆∞·ª£c, 
    ph√π h·ª£p cho vi·ªác x√¢y d·ª±ng chi·∫øn l∆∞·ª£c marketing ri√™ng bi·ªát.
    """)

def show_cluster_profiling(data):
    """Hi·ªÉn th·ªã profiling v√† di·ªÖn gi·∫£i c·ª•m"""
    st.markdown('<h2 class="section-title">üë• 4. Profiling & Di·ªÖn gi·∫£i C·ª•m</h2>', unsafe_allow_html=True)
    
    if 'cluster_profiles' not in data or data['cluster_profiles'].empty:
        st.error("‚ùå Kh√¥ng c√≥ d·ªØ li·ªáu cluster profiles")
        return
    
    # B·∫£ng th·ªëng k√™ theo c·ª•m
    st.markdown("### üìä B·∫£ng th·ªëng k√™ theo c·ª•m")
    
    required_cols = ['cluster', 'n_customers']
    for col in required_cols:
        if col not in data['cluster_profiles'].columns:
            st.error(f"Thi·∫øu c·ªôt {col} trong cluster_profiles")
            return
    
    # Chu·∫©n b·ªã d·ªØ li·ªáu hi·ªÉn th·ªã
    display_cols = ['cluster', 'n_customers']
    
    # Th√™m c√°c c·ªôt RFM n·∫øu c√≥
    rfm_cols = ['avg_recency', 'avg_frequency', 'avg_monetary']
    for col in rfm_cols:
        if col in data['cluster_profiles'].columns:
            display_cols.append(col)
    
    # Th√™m percentage
    if 'customer_percentage' not in data['cluster_profiles'].columns:
        total = data['cluster_profiles']['n_customers'].sum()
        data['cluster_profiles']['customer_percentage'] = data['cluster_profiles']['n_customers'] / total
    
    display_cols.append('customer_percentage')
    
    # Hi·ªÉn th·ªã b·∫£ng
    display_df = data['cluster_profiles'][display_cols].copy()
    
    # Format c√°c c·ªôt
    if 'avg_recency' in display_df.columns:
        display_df['avg_recency'] = display_df['avg_recency'].apply(lambda x: f"{int(x)} ng√†y" if pd.notna(x) else "N/A")
    if 'avg_monetary' in display_df.columns:
        display_df['avg_monetary'] = display_df['avg_monetary'].apply(lambda x: f"¬£{x:.1f}" if pd.notna(x) else "N/A")
    if 'customer_percentage' in display_df.columns:
        display_df['customer_percentage'] = display_df['customer_percentage'].apply(lambda x: f"{x:.1%}" if pd.notna(x) else "N/A")
    
    st.dataframe(
        display_df,
        column_config={
            'cluster': 'C·ª•m',
            'n_customers': 'S·ªë KH',
            'customer_percentage': 'T·ª∑ l·ªá',
            'avg_recency': 'Recency TB',
            'avg_frequency': 'Frequency TB',
            'avg_monetary': 'Monetary TB'
        },
        width='stretch',
        hide_index=True
    )
    
    # Profiling t·ª´ng c·ª•m
    st.markdown("### üè∑Ô∏è Profiling chi ti·∫øt t·ª´ng c·ª•m")
    
    tabs = st.tabs([f"C·ª•m {i}" for i in sorted(data['cluster_profiles']['cluster'].unique())])
    
    cluster_names = {
        0: {'vi': 'Kh√°ch VIP Trung th√†nh', 'en': 'VIP Loyal Customers'},
        1: {'vi': 'Kh√°ch Th∆∞·ªùng xuy√™n', 'en': 'Regular Customers'},
        2: {'vi': 'Kh√°ch Ng·ªß ƒë√¥ng', 'en': 'Inactive Customers'},
        3: {'vi': 'Kh√°ch Ti·ªÅm nƒÉng', 'en': 'Potential Customers'}
    }
    
    cluster_personas = {
        0: 'Kh√°ch h√†ng gi√° tr·ªã cao, mua th∆∞·ªùng xuy√™n, recency th·∫•p, monetary cao',
        1: 'Kh√°ch h√†ng trung th√†nh, t·∫ßn su·∫•t mua ·ªïn ƒë·ªãnh, gi√° tr·ªã trung b√¨nh',
        2: 'Kh√°ch h√†ng l√¢u kh√¥ng mua, c·∫ßn chi·∫øn d·ªãch re-activation',
        3: 'Kh√°ch h√†ng m·ªõi, c√≥ ti·ªÅm nƒÉng ph√°t tri·ªÉn th√†nh loyal customers'
    }
    
    for idx, cluster_id in enumerate(sorted(data['cluster_profiles']['cluster'].unique())):
        with tabs[idx]:
            cluster_data = data['cluster_profiles'][data['cluster_profiles']['cluster'] == cluster_id]
            if cluster_data.empty:
                st.warning(f"Kh√¥ng c√≥ d·ªØ li·ªáu cho c·ª•m {cluster_id}")
                continue
            
            profile = cluster_data.iloc[0]
            
            col1, col2 = st.columns([2, 1])
            
            with col1:
                st.markdown(f"#### üéØ {cluster_names.get(cluster_id, {}).get('vi', f'C·ª•m {cluster_id}')}")
                st.markdown(f"*{cluster_names.get(cluster_id, {}).get('en', f'Cluster {cluster_id}')}*")
                
                st.markdown("**Persona:**")
                st.info(cluster_personas.get(cluster_id, "Kh√¥ng c√≥ m√¥ t·∫£"))
                
                # Hi·ªÉn th·ªã top rules cho c·ª•m n√†y
                if 'top_rules' in data and not data['top_rules'].empty:
                    st.markdown("**Top 3 rules ƒë·∫∑c tr∆∞ng:**")
                    
                    # L·∫•y top 3 rules (v√≠ d·ª•)
                    for i in range(1, 4):
                        rule_idx = (cluster_id * 3 + i) % len(data['top_rules'])
                        if rule_idx < len(data['top_rules']):
                            rule = data['top_rules'].iloc[rule_idx]
                            st.write(f"{i}. **N·∫øu mua:** {rule.get('antecedents_str', 'N/A')[:50]}...")
                            st.write(f"   **Th√¨ mua:** {rule.get('consequents_str', 'N/A')[:50]}...")
                            st.write(f"   (Confidence: {rule.get('confidence', 0):.1%}, Lift: {rule.get('lift', 0):.2f})")
            
            with col2:
                st.metric("S·ªë KH", f"{profile.get('n_customers', 0):,}")
                if 'customer_percentage' in profile:
                    st.metric("T·ª∑ l·ªá", f"{profile['customer_percentage']:.1%}")
                
                # RFM metrics
                if 'avg_recency' in profile:
                    st.metric("Recency TB", f"{profile['avg_recency']:.0f} ng√†y")
                if 'avg_monetary' in profile:
                    st.metric("Monetary TB", f"¬£{profile['avg_monetary']:.1f}")

def show_marketing_strategies(data):
    """Hi·ªÉn th·ªã chi·∫øn l∆∞·ª£c marketing"""
    st.markdown('<h2 class="section-title">üöÄ 5. ƒê·ªÅ xu·∫•t Chi·∫øn l∆∞·ª£c Marketing</h2>', unsafe_allow_html=True)
    
    if 'marketing_recomm' not in data or data['marketing_recomm'].empty:
        st.error("‚ùå Kh√¥ng c√≥ d·ªØ li·ªáu marketing recommendations")
        return
    
    # Hi·ªÉn th·ªã t·∫•t c·∫£ recommendations
    for _, rec in data['marketing_recomm'].iterrows():
        cluster_id = rec['cluster']
        
        with st.expander(f"üéØ Chi·∫øn l∆∞·ª£c cho C·ª•m {cluster_id}: {rec.get('strategy_type', 'N/A')}"):
            col1, col2 = st.columns([3, 1])
            
            with col1:
                st.markdown(f"**ƒê·ªÅ xu·∫•t:** {rec.get('recommendation', 'N/A')}")
                st.markdown(f"**L√Ω do:** {rec.get('rationale', 'N/A')}")
            
            with col2:
                st.metric("Expected KPI", rec.get('expected_kpi', 'N/A'))
            
            # Th√™m chi ti·∫øt c·ª• th·ªÉ cho t·ª´ng c·ª•m
            if cluster_id == 0:  # VIP Customers
                st.markdown("""
                **Chi·∫øn l∆∞·ª£c c·ª• th·ªÉ:**
                - Bundle s·∫£n ph·∫©m cao c·∫•p v·ªõi discount 15%
                - Early access cho s·∫£n ph·∫©m m·ªõi
                - Personal shopper service
                - Exclusive events invitation
                """)
            elif cluster_id == 1:  # Regular Customers
                st.markdown("""
                **Chi·∫øn l∆∞·ª£c c·ª• th·ªÉ:**
                - Loyalty program v·ªõi ƒëi·ªÉm t√≠ch l≈©y
                - Cross-sell recommendations tr√™n website
                - Email marketing h√†ng tu·∫ßn
                - Birthday discount 20%
                """)
            elif cluster_id == 2:  # Inactive Customers
                st.markdown("""
                **Chi·∫øn l∆∞·ª£c c·ª• th·ªÉ:**
                - "We miss you" email v·ªõi 25% discount
                - Survey ƒë·ªÉ hi·ªÉu l√Ω do kh√¥ng mua
                - Re-activation campaign
                - Limited time offers
                """)
            elif cluster_id == 3:  # Potential Customers
                st.markdown("""
                **Chi·∫øn l∆∞·ª£c c·ª• th·ªÉ:**
                - Welcome package v·ªõi 15% discount
                - Educational content v·ªÅ s·∫£n ph·∫©m
                - Product recommendations based on browsing history
                - Trial size/sample offers
                """)
    
    # Bundle recommendations
    st.markdown("### üì¶ ƒê·ªÅ xu·∫•t Bundle & Cross-Sell")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("#### Bundle theo c·ª•m")
        
        bundle_suggestions = [
            ("C·ª•m 0 (VIP)", "Luxury Home Decor Bundle", "WHITE HANGING HEART + REGENCY CAKESTAND + Gift Wrap", "-20%"),
            ("C·ª•m 1 (Regular)", "Kitchen Essentials Pack", "SET OF 3 TINS + CAKE STAND + Measuring Spoons", "-15%"),
            ("C·ª•m 2 (Inactive)", "Welcome Back Bundle", "Best Seller + Free Shipping + Extra Gift", "-25%"),
            ("C·ª•m 3 (Potential)", "Starter Kit", "Popular Item + Guide Book + 1-on-1 Consultation", "-15%")
        ]
        
        for cluster, bundle, items, discount in bundle_suggestions:
            st.markdown(f"""
            <div class="strategy-card">
                <h5>{bundle} - {cluster}</h5>
                <p><strong>Includes:</strong> {items}</p>
                <p><strong>Discount:</strong> {discount}</p>
            </div>
            """, unsafe_allow_html=True)
    
    with col2:
        st.markdown("#### Cross-Sell Opportunities")
        
        if 'top_rules' in data and not data['top_rules'].empty:
            top_cross_sell = data['top_rules'].sort_values('lift', ascending=False).head(5)
            
            for idx, (_, rule) in enumerate(top_cross_sell.iterrows(), 1):
                # X·ª≠ l√Ω frozenset string ƒë√∫ng c√°ch
                def extract_items(fset_str):
                    """Extract items from frozenset string"""
                    try:
                        # Lo·∫°i b·ªè 'frozenset({' v√† '})'
                        items_str = str(fset_str).replace("frozenset({", "").replace("})", "")
                        # Lo·∫°i b·ªè d·∫•u nh√°y v√† d·∫•u c√°ch th·ª´a
                        items = items_str.replace("'", "").replace('"', '').split(", ")
                        # Join l·∫°i th√†nh chu·ªói ƒë·∫πp
                        return ", ".join(filter(None, items))
                    except:
                        return str(fset_str)[:50]
                
                antecedents_clean = extract_items(rule.get('antecedents_str', ''))
                consequents_clean = extract_items(rule.get('consequents_str', ''))
                
                st.markdown(f"""
                <div class="rule-card">
                    <h6>Opportunity {idx}</h6>
                    <p><strong>Kh√°ch mua:</strong> {antecedents_clean}</p>
                    <p><strong>ƒê·ªÅ xu·∫•t:</strong> {consequents_clean}</p>
                    <p><small>Confidence: {rule.get('confidence', 0):.1%} | Lift: {rule.get('lift', 0):.2f}</small></p>
                </div>
                """, unsafe_allow_html=True)

def show_dashboard_features(data):
    """Hi·ªÉn th·ªã c√°c t√≠nh nƒÉng dashboard"""
    st.markdown('<h2 class="section-title">üì± 6. Dashboard Features</h2>', unsafe_allow_html=True)
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("""
        ### üîç L·ªçc & Kh√°m ph√°
        - L·ªçc theo c·ª•m kh√°ch h√†ng
        - Xem chi ti·∫øt t·ª´ng segment
        - Danh s√°ch kh√°ch h√†ng trong c·ª•m
        - Export d·ªØ li·ªáu theo c·ª•m
        """)
    
    with col2:
        st.markdown("""
        ### üìä Visualization
        - Ph√¢n b·ªë c·ª•m (bar chart, pie chart)
        - PCA visualization
        - RFM metrics dashboard
        - Rules distribution
        """)
    
    with col3:
        st.markdown("""
        ### üöÄ Actionable Insights
        - Chi·∫øn l∆∞·ª£c marketing theo c·ª•m
        - Bundle recommendations
        - Cross-sell opportunities
        - KPI tracking
        """)
    
    # Interactive features demo
    st.markdown("### üéÆ T√≠nh nƒÉng t∆∞∆°ng t√°c")
    
    tab1, tab2, tab3 = st.tabs(["Rules Explorer", "Cluster Filter", "Bundle Generator"])
    
    with tab1:
        if 'top_rules' in data and not data['top_rules'].empty:
            search_product = st.text_input("üîç T√¨m ki·∫øm s·∫£n ph·∫©m trong rules:")
            
            if search_product:
                mask = (
                    data['top_rules']['antecedents_str'].astype(str).str.contains(search_product, case=False, na=False) |
                    data['top_rules']['consequents_str'].astype(str).str.contains(search_product, case=False, na=False)
                )
                
                matching_rules = data['top_rules'][mask]
                
                if not matching_rules.empty:
                    st.success(f"T√¨m th·∫•y {len(matching_rules)} rules cho '{search_product}'")
                    st.dataframe(matching_rules.head(10), width='stretch', hide_index=True)
                else:
                    st.info(f"Kh√¥ng t√¨m th·∫•y rules cho '{search_product}'")
    
    with tab2:
        if 'cluster_results' in data and 'cluster' in data['cluster_results'].columns:
            selected_cluster = st.selectbox(
                "Ch·ªçn c·ª•m ƒë·ªÉ xem kh√°ch h√†ng:",
                sorted(data['cluster_results']['cluster'].unique())
            )
            
            cluster_customers = data['cluster_results'][data['cluster_results']['cluster'] == selected_cluster]
            
            st.metric(f"S·ªë kh√°ch h√†ng C·ª•m {selected_cluster}", len(cluster_customers))
            
            if st.checkbox("Hi·ªÉn th·ªã danh s√°ch kh√°ch h√†ng"):
                st.dataframe(cluster_customers[['CustomerID']].head(20), width='stretch', hide_index=True)
    
    with tab3:
        st.markdown("T·∫°o bundle t√πy ch·ªânh:")
        
        col1, col2 = st.columns(2)
        
        with col1:
            base_product = st.selectbox("S·∫£n ph·∫©m ch√≠nh:", 
                                      ["WHITE HANGING HEART", "JUMBO BAG RED", "REGENCY CAKESTAND", "SET OF 3 TINS"])
        
        with col2:
            addon = st.selectbox("S·∫£n ph·∫©m k√®m theo:", 
                               ["Gift Wrapping", "Related Accessory", "Maintenance Kit", "Extended Warranty"])
        
        discount = st.slider("Discount (%)", 0, 50, 20)
        
        if st.button("T·∫°o Bundle", type="primary"):
            st.success(f"‚úÖ Bundle created: {base_product} + {addon}")
            st.info(f"üì¶ Gi√° bundle: Gi·∫£m {discount}% khi mua combo")
            st.info(f"üéØ Target: T·∫•t c·∫£ kh√°ch h√†ng (c√≥ th·ªÉ t√πy ch·ªânh theo c·ª•m)")

# ==================== MAIN APP ====================
def main():
    """Main application"""
    
    # Sidebar
    with st.sidebar:
        st.markdown("## üéØ ƒêi·ªÅu h∆∞·ªõng - Nh√≥m 13")
        
        section = st.radio(
            "Ch·ªçn ph·∫ßn tr√¨nh b√†y:",
            [
                "üìã T·ªïng quan Project",
                "üîó 1. Lu·∫≠t k·∫øt h·ª£p",
                "‚öôÔ∏è 2. Feature Engineering", 
                "üéØ 3. Ph√¢n c·ª•m",
                "üë• 4. Profiling",
                "üöÄ 5. Marketing",
                "üì± 6. Dashboard"
            ]
        )
        
        st.markdown("---")
        st.markdown("### üìà Th√¥ng tin h·ªá th·ªëng")
        
        # Load data v·ªõi progress
        with st.spinner("ƒêang t·∫£i d·ªØ li·ªáu..."):
            data = load_data()
        
        if data is None:
            st.error("‚ùå Kh√¥ng th·ªÉ t·∫£i d·ªØ li·ªáu")
            st.info("""
            Vui l√≤ng ch·∫°y pipeline ƒë·ªÉ t·∫°o d·ªØ li·ªáu:
            1. Ch·∫°y notebook 3-4: T·∫°o association rules
            2. Ch·∫°y notebook 5: Feature engineering
            3. Ch·∫°y notebook 6: Clustering
            4. Ch·∫°y notebook 7: T·∫°o recommendations
            """)
            st.stop()
        
        # Quick stats
        if 'cluster_results' in data:
            st.metric("T·ªïng KH", f"{data['cluster_results']['CustomerID'].nunique():,}")
        
        if 'cluster_results' in data and 'cluster' in data['cluster_results'].columns:
            st.metric("S·ªë c·ª•m", data['cluster_results']['cluster'].nunique())
        
        if 'top_rules' in data:
            st.metric("S·ªë lu·∫≠t", len(data['top_rules']))
        
        st.markdown("---")
        st.markdown("#### üë• Th√†nh vi√™n Nh√≥m 13")
        st.info("""
        - Member 1
        - Member 2  
        - Member 3
        - Member 4
        - Member 5
        """)
    
    # Main content
    if section == "üìã T·ªïng quan Project":
        show_project_overview()
    
    elif section == "üîó 1. Lu·∫≠t k·∫øt h·ª£p":
        show_rule_selection(data)
    
    elif section == "‚öôÔ∏è 2. Feature Engineering":
        show_feature_comparison(data)
    
    elif section == "üéØ 3. Ph√¢n c·ª•m":
        show_clustering_analysis(data)
    
    elif section == "üë• 4. Profiling":
        show_cluster_profiling(data)
    
    elif section == "üöÄ 5. Marketing":
        show_marketing_strategies(data)
    
    elif section == "üì± 6. Dashboard":
        show_dashboard_features(data)
    
    # Footer
    st.markdown("---")
    st.markdown(
        """
        <div style='text-align: center; color: #666; padding: 1rem;'>
            <p>üìä <strong>Customer Segmentation Dashboard - Nh√≥m 13</strong></p>
            <p>üîÑ Pipeline: Rules ‚Üí Features ‚Üí Clustering ‚Üí Profiling ‚Üí Marketing</p>
            <p>‚è∞ Last updated: {}</p>
        </div>
        """.format(datetime.now().strftime("%Y-%m-%d %H:%M")),
        unsafe_allow_html=True
    )

if __name__ == "__main__":
    main()